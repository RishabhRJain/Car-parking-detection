{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49NNwxNG6ZjR"
   },
   "source": [
    "**To find empty Car parking spaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJH5HK2n638I"
   },
   "source": [
    "First, let us mount our google drive. To do the same you need to authorize colab to access your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "NHH9O_O5OU5O",
    "outputId": "0a8570da-e75e-4596-8e7a-2831459cb680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nx2M8M1z7YU9"
   },
   "source": [
    "Let us go to our project location. I have created a folder project --> Car detection in my google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b012O0VSOlwc",
    "outputId": "f142151a-2274-4ee4-85fc-1f1481477a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_detect.py\t logs\t     parking.mp4  test_images\n",
      "car_parking.mp4  output.mp4  rcnn.h5\t  wait.py\n"
     ]
    }
   ],
   "source": [
    "# After executing the cell above, Drive\n",
    "# files will be present in \"/content/drive/My Drive\".\n",
    "!ls \"/content/drive/My Drive/project/car detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5NlwN0b7v2t"
   },
   "source": [
    "Let us install mrcnn and twilio which are required for Car detection and Messaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "HPKU-kh9Ot_M",
    "outputId": "05dccb0d-a237-4918-8614-6f8b036654ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 993kB 10.1MB/s \n",
      "\u001b[?25h  Building wheel for mrcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q mrcnn twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrArNxJjO8JF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mrcnn.config\n",
    "import mrcnn.utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn import visualize\n",
    "from pathlib import Path\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_FK4rSfmDAI"
   },
   "source": [
    "Configure the RCNN model by setting some config parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7R5H2NHePCID"
   },
   "outputs": [],
   "source": [
    "class RCNNConfig(mrcnn.config.Config):\n",
    "    NAME = \"coco_pretrained_model_config\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES = 1 + 80  # COCO dataset has 80 classes + one background class\n",
    "    DETECTION_MIN_CONFIDENCE = 0.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jff-XYXSmUYb"
   },
   "source": [
    "The get_car_boxes returns objects which are only Car, Bus or Truck.\n",
    "\n",
    "Here is the list of\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlEH3s25mIKj"
   },
   "outputs": [],
   "source": [
    "def get_car_boxes(boxes, class_ids):\n",
    "    car_box = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if class_ids[i] in [3, 6, 8]:\n",
    "            car_box.append(box)\n",
    "\n",
    "\n",
    "    return np.array(car_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByBFp311tn_x"
   },
   "source": [
    "Setup your twilio account at https://www.twilio.com/ and configure it to send an SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ax188_4Oy6a"
   },
   "outputs": [],
   "source": [
    "# Twilio config\n",
    "twilio_account_sid = 'your twilio account sid'\n",
    "twilio_auth_token = 'twilio auth token'\n",
    "twilio_phone_number = 'FROM phone number'\n",
    "destination_phone_number = 'TO phone number'\n",
    "client = Client(twilio_account_sid, twilio_auth_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_VFAX744DcV"
   },
   "source": [
    "Load the model  and configure the input and output paths.\n",
    "**VIDEO_SOURCE** is the path where the input is stored in drive. \n",
    "**VIDEO_STREAM_OUT** is the path where the output video will be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QV2V-YLAPGPp"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/content/drive/My Drive/project/car detection\")\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")    \n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"rcnn.h5\")\n",
    "\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")    \n",
    "\n",
    "VIDEO_SOURCE = \"/content/drive/My Drive/project/car detection/car_parking.mp4\"\n",
    "VIDEO_STREAM_OUT = \"/content/drive/My Drive/project/car detection/test_images/output.avi\"\n",
    "\n",
    "\n",
    "model = MaskRCNN(mode = \"inference\", model_dir = MODEL_DIR, config = RCNNConfig())\n",
    "\n",
    "model.load_weights(COCO_MODEL_PATH, by_name = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJeFbvxb4y_B"
   },
   "source": [
    "The display_instances is the function which returns the image with the bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8PP63WHc_gP"
   },
   "outputs": [],
   "source": [
    "def display_instances(image, boxes):\n",
    "\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "\n",
    "    colors = visualize.random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "\n",
    "        if not np.any(boxes[i]):\n",
    "\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "\n",
    "        #label = names[ids[i]]\n",
    "\n",
    "        #score = scores[i] if scores is not None else None\n",
    "\n",
    "        #caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "\n",
    "        #mask = masks[:, :, i]\n",
    "\n",
    "        #image = visualize.apply_mask(image, mask, color)\n",
    "\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLVQqJr05Q-9"
   },
   "source": [
    "The below part reads the input video and sends a text message if it finds a parking space!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xK36cNkmPY9z",
    "outputId": "5d343062-723f-409c-cf07-f9764d928a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free spaces frames =  1\n",
      "free spaces frames =  1\n",
      "free spaces frames =  2\n",
      "free spaces frames =  1\n",
      "free spaces frames =  2\n",
      "free spaces frames =  3\n",
      "Space available\n",
      "SENDING SMS...\n",
      "free spaces frames =  1\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "# Location of parking spaces\n",
    "parked_car_boxes = None\n",
    "\n",
    "# How many frames of video we've seen in a row with a parking space open\n",
    "free_space_frames = 0\n",
    "\n",
    "# Have we sent an SMS alert yet?\n",
    "sms_sent = False\n",
    "\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "writer = None\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color\n",
    "    rgb_image = frame[:, :, ::-1]        \n",
    "\n",
    "    # Run the image through the Mask R-CNN model to get results.\n",
    "    result = model.detect([rgb_image], verbose = 0)\n",
    "\n",
    "    r = result[0]\n",
    "\n",
    "    # The r variable will now have the results of detection:\n",
    "    # - r['rois'] are the bounding box of each detected object\n",
    "    # - r['class_ids'] are the class id (type) of each detected object\n",
    "    # - r['scores'] are the confidence scores for each detection\n",
    "    # - r['masks'] are the object masks for each detected object (which gives you the object outline)\n",
    "    \n",
    "    if parked_car_boxes is None:\n",
    "      #This is the first frame\n",
    "      parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "    \n",
    "    else:\n",
    "      # we already know where the parking spaces are\n",
    "      # \n",
    "      car_parking_spaces = get_car_boxes(r['rois'], r['class_ids'])\n",
    "      \n",
    "      overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_parking_spaces)\n",
    "      \n",
    "      # Assume no spaces are free until we find one that is free\n",
    "      free_space = False\n",
    "      \n",
    "      for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
    "        # For this parking space, find the max amount it was covered by any\n",
    "        # car that was detected in our image (doesn't really matter which car)\n",
    "        max_IoU_overlap = np.max(overlap_areas)\n",
    "        \n",
    "        if max_IoU_overlap < 0.15:\n",
    "          free_space = True\n",
    "         \n",
    "      if free_space:\n",
    "          free_space_frames += 1\n",
    "          print(\"free spaces frames = \" , free_space_frames)\n",
    "          \n",
    "      else:\n",
    "          free_space_frames = 0\n",
    "          \n",
    "      if free_space_frames > 2:\n",
    "          print(\"Space available\")\n",
    "          font = cv2.FONT_HERSHEY_DUPLEX\n",
    "          writer.write(cv2.putText(frame, f\"SPACE AVAILABLE!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED))\n",
    "          \n",
    "          if not sms_sent:\n",
    "            print(\"SENDING SMS...\")\n",
    "            message = client.messages.create(\n",
    "                    body=\"Parking space open - go go go!!\",\n",
    "                    from_=twilio_phone_number,\n",
    "                    to=destination_phone_number\n",
    "                )\n",
    "            sms_sent = True\n",
    "            \n",
    "      masked_frame = display_instances(frame, car_parking_spaces)\n",
    "\n",
    "    \n",
    "      if writer is None:\n",
    "          fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "          writer = cv2.VideoWriter(VIDEO_STREAM_OUT, fourcc, 30,(masked_frame.shape[1], masked_frame.shape[0]), True)\n",
    "\n",
    "      writer.write(masked_frame)\n",
    "\n",
    "\n",
    "    # Hit 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up everything when finished\n",
    "print(\"[INFO] cleaning up...\")\n",
    "writer.release()\n",
    "\n",
    "video_capture.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fD5EBePIgry2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06K3osGCPfVL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "car.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
